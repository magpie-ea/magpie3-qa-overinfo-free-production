---
title: "Prior Elicitation Pilot 2"
author: "PT"
date: "2022-11-20"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include = FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidyboot)
library(aida)
library(forcats)
library("gridExtra")
```

```{r, include=FALSE}
# these options help Stan run faster
options(mc.cores = parallel::detectCores())

# use the aida-theme for plotting
theme_set(theme_aida())

# global color scheme / non-optimized
project_colors = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#000000")

# setting theme colors globally
scale_colour_discrete <- function(...) {
  scale_colour_manual(..., values = project_colors)
}
scale_fill_discrete <- function(...) {
  scale_fill_manual(..., values = project_colors)
} 
```


## Prior Elicitation Pilot 2

This pilot follows up on the results from the [first prior elicitation pilot](https://github.com/magpie-ea/magpie3-qa-overinfo-free-production/blob/main/data%2Banalysis/02_main_prior_eliciation_analysis.md) (N=80).

The goal of the follow up is to improve the interpretability of the signal we are eliciting for using the ratings as parameters of the RSA model. More specifically, the context of the vignettes was removed and the background and question formulations were updated to e.g. "Suppose someone wants to have raspberry pie" - "How happy do you think they would be if instead they got X?". This framing might better tap into the similarity of the alternatives. Only the words "to have" in the context might vary across vignettes. Participants responded on a slider ranging from "much less happy" to "much happier", centered at "equally happy".

Furthermore, each participant only saw three sliders: competitor, a randomly sampled same-category option and a randomly sampled other-category option. 

For piloting purposes, only four vignettes were selected and 20 subjects who saw all vignettes and one attention check were recruited. The four vignettes consisted on two good vignettes (according to prior free-production + prior elicitation performance) -- cafe-pie and electronics-laptop -- and two bad vignettes -- furniture-outdoors and plants-green. 

```{r, include = FALSE, message=FALSE, warning=FALSE}
answerOrder <- c( 'competitor', 'sameCategory1', 'sameCategory2', 'otherCategory1', 'otherCategory2')
#df <- read_csv("../../raw_data/results_99_QA-overinformative-priorElicitation-magpie-pilot02_PT.csv") 
#df %>% select(-prolific_pid, -prolific_session_id, -prolific_study_id) %>% filter(is.na(comments)) %>% write_csv("results_99_QA-overinformative-priorElicitation-magpie-pilot02_20_anonymized.csv")

df <- read_csv("results_99_QA-overinformative-priorElicitation-magpie-pilot02_20_anonymized.csv")
head(df)
cat("Number of recruited subjects: ", df %>% pull(submission_id) %>% unique() %>% length())
```

```{r, include = FALSE, message=FALSE, warning=FALSE}
# check attention check completion
df <- df %>% mutate(
  expected_attention = case_when(
    itemName == 'jobCenter-office' ~ 0,
    itemName == 'jobCenter-engineer' ~ 0,
    itemName == 'art-painting' ~ 100,
    itemName == 'art-drawing' ~ 100,
    itemName == 'carRental-fun' ~ 0,
    itemName == 'carRental-moving' ~ 0,
    itemName == 'music-hardrock' ~ 100,
    itemName == 'music-softrock' ~ 100,
    itemName == 'airport-usa' ~ 0,
    itemName == 'airport-europe' ~ 100,
    TRUE ~ 50
  )
)

df_attention <- df %>% filter(trial_type == "filler") %>% 
  select(submission_id, competitor, sameCategory1, sameCategory2, otherCategory1, otherCategory2, expected_attention, itemName) %>% 
  pivot_longer(cols = c(competitor, sameCategory1, sameCategory2, otherCategory1, otherCategory2), names_to = "answerType", values_to = "response") %>%
  rowwise() %>%
  mutate(passed_trial = abs(response - expected_attention) < 5 )

df_attention_fail <- df_attention %>% group_by(submission_id) %>% 
  mutate(passed_subj = sum(passed_trial) > 0)

# participants who failed attention checks 
subj_id_attention_fails <- df_attention_fail %>% filter(passed_subj == FALSE) %>% pull(submission_id) %>% unique()
cat("Numbrer of subjects who failed attention checks: ", length(subj_id_attention_fails)  )
cat("\nSubject exclusion rate: ", length(subj_id_attention_fails)/(unique(df$submission_id) %>% length()))
```

```{r, echo=FALSE, include = FALSE, message=FALSE, warning=FALSE}
# get main clean data and center responses
df_clean_main <- df %>% filter(!(submission_id %in% subj_id_attention_fails)) %>%
  filter(trial_type == "main") 

df_clean_main_long <- df_clean_main %>%
  select(itemName, trialNr, submission_id, competitor, sameCategory1, sameCategory2, otherCategory1, otherCategory2) %>%
   pivot_longer(cols = c(competitor, sameCategory1, sameCategory2, otherCategory1, otherCategory2), names_to = 'answerType', values_to = "response") %>%
  mutate(
    centered_response = response - 50,
    answerType = case_when(
      answerType == "sameCategory1" ~ "sameCategory",
      answerType == "sameCategory2" ~ "sameCategory",
      answerType == "otherCategory1" ~ "otherCategory",
      answerType == "otherCategory2" ~ "otherCategory",
      TRUE ~ answerType
    )
  ) %>%
  filter(!is.na(response))
```

```{r, echo=FALSE}
df_bad_subj <- df_clean_main_long %>% group_by(submission_id) %>%
  mutate(bad_subj = (max(response) - min(response)) < 5)
df_bad_subj %>% filter(bad_subj == TRUE)
cat("\nnumber of subjects who provided the same responses within 5 points on all main trials:",  df_bad_subj %>% filter(bad_subj == TRUE) %>% pull(submission_id) %>% unique() %>% length())
bad_subj_ids <- df_bad_subj %>% filter(bad_subj == TRUE) %>% pull(submission_id) %>% unique()

df_clean_main <- df_clean_main %>% filter(!(submission_id %in% bad_subj_ids))
df_clean_main_long <- df_clean_main_long %>% filter(!(submission_id %in% bad_subj_ids))

```
```{r, echo=FALSE}
cat("\nNumber of analysed vignette responses: ", nrow(df_clean_main))

df_clean_main %>% count(itemName) 

cat("\naverage number of responses per vignette:", mean(df_clean_main %>% count(itemName) %>% pull(n)))

```
## Plots

Plot the raw ratings and by-vignette by-answerType means. Error bars are bootstrapped 95%-CrIs.
```{r, fig.height = 7, fig.width=8, echo=FALSE, warning=FALSE, message=FALSE}
df_clean_main_long_summary <- df_clean_main_long %>%
  group_by(answerType, itemName) %>%
  tidyboot_mean(column = response)
  #summarize(mean = mean(centered_response))

num_subj <- df_clean_main_long %>% pull(submission_id) %>% unique() %>% length()
df_clean_main_long <- df_clean_main_long %>% ungroup() %>%
  mutate(by_trial_nr = rep(1:(num_subj*4), each = 3),
         by_trial_nr = factor(by_trial_nr)
         )
  
df_clean_main_long %>% 
  mutate(answerType = factor(answerType, 
                             levels = c("competitor", "sameCategory", "otherCategory"))) %>%
  ggplot(., aes(x = answerType, y = response, color = answerType)) + 
  geom_point(alpha = 0.85) +
  geom_point(data = df_clean_main_long_summary, aes(x = answerType, y = mean), size = 4) +
  geom_errorbar(data = df_clean_main_long_summary,  aes(x = answerType, y = mean, ymin=ci_lower, ymax=ci_upper), width = 0.2) +
  geom_line(data = df_clean_main_long, inherit.aes=F, aes(x = answerType, y = response, group=by_trial_nr), alpha  = 0.4) + 
  facet_wrap(itemName ~ ., ncol = 2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(strip.text.x = element_text(size = 10)) +
  theme(panel.spacing = unit(2, "lines")) +
  ylab("Raw ratings") +
  ylim(0, 100) +
  xlab("Alternative type")
```

Compare results of current pilot (pilot 2) with new question formulation to results from first prior elicitation experiment (pilot 1) for the respective items (color, x-axis). Given the clearer formulation of the current pilot, one could expect a higher concentration of competitor ratings arounfd 50 and other ratings to be rather below 50.
```{r, fig.height = 7, fig.width=8, echo=FALSE}
df_pilot1 <- read_csv("results_QA-overinfo-priorElicitation-magpie-80_anonymized_clean_long.csv") %>%
  filter(itemName  %in% c("cafe-pie", "electronics-laptop", "furniture-outdoors", "plants-green")) %>%
  mutate(expt = "pilot 1",
         answerType = case_when(
      answerType == "sameCategory1" ~ "sameCategory",
      answerType == "sameCategory2" ~ "sameCategory",
      answerType == "otherCategory1" ~ "otherCategory",
      answerType == "otherCategory2" ~ "otherCategory",
      TRUE ~ answerType),
    expt = factor(expt, levels = c("pilot 1", "pilot 2")))

df_pilot1_summary <- df_pilot1 %>% 
  mutate(answerType = case_when(
      answerType == "sameCategory1" ~ "sameCategory",
      answerType == "sameCategory2" ~ "sameCategory",
      answerType == "otherCategory1" ~ "otherCategory",
      answerType == "otherCategory2" ~ "otherCategory",
      TRUE ~ answerType
    ),
    answerType = factor(answerType, 
                             levels = c("competitor", "sameCategory", "otherCategory")),
    expt = "pilot 1"
    ) %>%
  group_by(itemName, answerType, expt) %>%
  summarize(mean = mean(centered_response))

# plot against each other
df_clean_main_long_summary <- df_clean_main_long %>% group_by(itemName, answerType) %>%
  summarize(mean = mean(centered_response)) %>% unique() %>% mutate(expt = "pilot 2") 
df_clean_main_long <- df_clean_main_long %>% mutate(expt = "pilot 2")

df_bothPilots <- rbind(df_clean_main_long %>% select(-by_trial_nr, -trialNr), df_pilot1)
df_bothPilots_summaries <- rbind(df_clean_main_long_summary, df_pilot1_summary)

df_bothPilots %>% 
  mutate(answerType = factor(answerType, 
                             levels = c("competitor", "sameCategory", "otherCategory")),
         expt = factor(expt, levels = c("pilot 1", "pilot 2"))) %>%
  ggplot(., aes(x = answerType, y = centered_response, color = expt, fill = expt)) +
  geom_point(alpha = 0.7, position = position_jitterdodge(dodge.width = 0.8, jitter.width = 0.2)) +
  geom_point(data = df_bothPilots_summaries, aes(x = answerType, y = mean, color = expt), size = 3, position = position_jitterdodge(dodge.width = 0.8, jitter.width = 0.2)) +
  facet_wrap(itemName ~ ., ncol = 2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(strip.text.x = element_text(size = 10)) +
  theme(panel.spacing = unit(2, "lines")) +
  ylab("Raw ratings") +
  ylim(-50, 50) +
  xlab("Alternative type")
```

Compare results of this pilot to free production data of respective items.
```{r, fig.height = 7, fig.width=8, message=FALSE, echo=FALSE, warning=FALSE}
d_clean_main_collapsedCompetitor_summary_100 <- read_csv("d_clean_main_collapsedCompetitor_summary_100.csv") %>%
  filter(itemName  %in% c("cafe-pie", "electronics-laptop", "furniture-outdoors", "plants-green")) %>% 
  add_row(itemName = c("cafe-pie", "electronics-laptop", "furniture-outdoors", "plants-green"), responseCategory_proportion = c(0, 0, 0, 0), answerType = c("otherCategory", "otherCategory", "otherCategory", "otherCategory"))

df_clean_main_long_scaled <- df_clean_main_long %>%
  mutate(response = response/100,
         answerType = factor(answerType, levels = c('competitor', 'sameCategory', 'otherCategory', 'fullList', 'other', 'taciturn')))

df_clean_main_long_scaled_summary <- df_clean_main_long_scaled %>%
  group_by(itemName, answerType) %>%
  summarize(mean = mean(response))

d_clean_main_collapsedCompetitor_summary_100 %>% 
  mutate(answerType = factor(answerType, levels=c('competitor', 'sameCategory', 'otherCategory', 'fullList', 'other', 'taciturn'))) %>%
  ggplot(aes(x = answerType, 
             fill = answerType, 
             y = responseCategory_proportion)) +
  geom_col(alpha=0.75) +
  geom_point(data=df_clean_main_long_scaled, aes(x=answerType, y = response, color = answerType), size=2, alpha=0.5) +
  geom_point(data=df_clean_main_long_scaled_summary, aes(x=answerType, y = mean, color = answerType), size=3.5) +
  geom_hline(yintercept = 0.5, linetype='dashed') +
  facet_wrap( itemName ~ . , ncol = 2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(strip.text.x = element_text(size = 10)) +
  theme(panel.spacing = unit(3, "lines")) +
  theme(legend.position="none") +
  ylab("Proportion of answer types") +
  ylim(0, 1) +
  xlab("Answer type free production and prior ratings")
```

Write out means file for fitting RSA model (note that the z-scoring is by-vignette, not grouped by answer-type).
```{r, message=FALSE, warning=FALSE}
df_clean_main_long_zScored <- df_clean_main_long %>% 
  group_by(itemName) %>%
  mutate(mean = mean(response),
         sd = sd(response),
         response_zscored = (response - mean) / sd,
         response_zscored = ifelse(is.na(response_zscored), 0, response_zscored),
         ) %>%
  group_by(itemName, answerType) %>%
  mutate(mean_response = mean(response),
         mean_zScored = mean(response_zscored))

df_clean_main_long_zScored_unique <- df_clean_main_long_zScored %>% 
  select(itemName, answerType, mean_response, mean_zScored) %>% unique()

# df_clean_main_long_zScored_unique %>% write_csv("priorElicitation_pilot2_byVignette_byCategory_means.csv")
```