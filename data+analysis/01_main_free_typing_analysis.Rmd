---
title: "QA free typing analysis"
author: "Polina Tsvilodub"
date: '2022-11-01'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(tidyverse)
library(tidyboot)
library(aida)
```

```{r, include=FALSE}
# these options help Stan run faster
options(mc.cores = parallel::detectCores())

# use the aida-theme for plotting
theme_set(theme_aida())

# global color scheme / non-optimized
project_colors = c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#000000")

# setting theme colors globally
scale_colour_discrete <- function(...) {
  scale_colour_manual(..., values = project_colors)
}
scale_fill_discrete <- function(...) {
  scale_fill_manual(..., values = project_colors)
} 
```

# Intro

Below, exploratory analysis of the free production QA experiment data can be found.

The responses were manually classified by Polina into seven categories: 

* The "taciturn" category includes "No, we don't have XY" responses. It also subsumes the responses which include some kind of explanation (like "Moana isn’t here today, she is helping her islanders so can’t be with us."). 
* The "competitor" category includes responses offering the competitor instead of the target object. It includes responses where the alternative is the anticipated competitor.
* exploratory: The "competitor/other" category includes responses where either additional information was included next to offering the competitor or the named competitor differed from our preclassification.
* The "sameCategory" option includes responses offering several alternatives (2-3) from the same category or offering one option which I did not consider a direct competitor.
* The "otherCategory" option includes responses offering 1-2 alternatives from the different category.
* The "fullList" option includes responses where all alternatives were presented.
* The "other" category includes other unclassifiable responses as well as responses trying to offer some kind of vague solution to the request on top of saying "No" (like "We sell a selection of different types of books, I am sure you will find something in the adventure section.").

The standard analysis with one "competitor" category is compared to an analysis making the distinction between the two competitor-containing categories. Additionally, single responses were classified as incorrect with the "yes" category (e.g., "Yes let's go see it" for the zoo-xl vignette).

## Summary and exclusions

```{r, include=FALSE, warning=FALSE, message=FALSE}
answerOrder <- c( 'competitor', 'competitor/other', 'sameCategory', 'otherCategory', 'fullList', 'other', 'taciturn')
#df100 <- read_csv("results_5_QA-overinfo-freeTyping-extendedExpt_100.csv")
#df100 %>% filter(answer != "ptsv") %>% select(-prolific_pid, -prolific_session_id, -prolific_study_id) %>%  write_csv("results_QA-overinfo-freeTyping-extendedExpt_100_anonymized.csv")

df <- read_csv("results_QA-overinfo-freeTyping-extendedExpt_100_anonymized_categorized.csv")
head(df)
cat("Number of recruited subjects: ", df %>% pull(submission_id) %>% unique() %>% length())
```

```{r, echo=FALSE}
# check attention check completion
df_attention <- df %>% filter(trial_type == "filler") %>% rowwise() %>%
  mutate(passed_trial = grepl(tolower(correct_response), tolower(answer))) 

df_attention_fail <- df_attention %>% group_by(submission_id) %>% 
  mutate(passed_subj = sum(passed_trial) > 0)

# participants who failed attention checks 
subj_id_attention_fails <- df_attention_fail %>% filter(passed_subj == FALSE) %>% pull(submission_id) %>% unique()
cat("Subjects who failed attention checks: ", subj_id_attention_fails)  
cat("\nSubject exclusion rate: ", length(subj_id_attention_fails)/(unique(df$submission_id) %>% length()))
```

```{r, echo=FALSE}
cat("Number of excluded inccorect ('yes') responses: ", nrow(df %>% filter(category == "yes")))

# exclude failing participnats and incorrect ("yes") responses
df_clean_main <- df %>% filter(!(submission_id %in% subj_id_attention_fails)) %>%
  filter(trial_type == "main", category != "yes")

cat("\nNumber of analysed responses: ", nrow(df_clean_main))

df_clean_main %>% count(category)

df_clean_main %>% count(itemName) 

cat("\naverage number of responses per vignette:", mean(df_clean_main %>% count(itemName) %>% pull(n)))

cat("\nvignette with most responses: ", df_clean_main %>% count(itemName) %>% arrange(desc(n)) %>% .[1,] %>% .$itemName, df_clean_main %>% count(itemName) %>% arrange(desc(n)) %>% .[1,] %>% .$n)
cat("\nvignette with least responses: ", df_clean_main %>% count(itemName) %>% arrange(n) %>% .[1,] %>% .$itemName, df_clean_main %>% count(itemName) %>% arrange(n) %>% .[1,] %>% .$n)
```
 
## Plots

The first plot displays proportions of different response types (standard analysis) by-vignette. 

```{r, echo=FALSE, fig.height=28, fig.width=12}
df_clean_main <- df_clean_main %>% group_by(itemName) %>%
  mutate(response_count = n(), 
         answerType = factor(category, levels = answerOrder)) %>% ungroup()
  

df_clean_main_summary <- df_clean_main %>% group_by(itemName, answerType) %>% 
  mutate(responseCategory_count = n(),
         responseCategory_proportion = responseCategory_count / response_count
         ) %>% ungroup() %>%
  select(itemName, answerType, responseCategory_proportion) %>% unique()
```

```{r, echo=FALSE, fig.height=28, fig.width=12}
# collapsing across the two competitor categories
d_clean_main_collapsedCompetitor <- df_clean_main %>% rowwise() %>% mutate(
  answerType = ifelse(category == "competitor/other", "competitor", category)
) %>% group_by(itemName, answerType) %>% 
  mutate(responseCategory_count = n(),
         responseCategory_proportion = responseCategory_count / response_count
         ) %>% ungroup()

d_clean_main_collapsedCompetitor_summary <- d_clean_main_collapsedCompetitor %>%
  group_by(itemName, answerType) %>%
  mutate(responseCategory_count = n(),
         responseCategory_proportion = responseCategory_count / response_count,
         answerType = factor(answerType, levels = answerOrder)
         ) %>%
  select(itemName, answerType, responseCategory_proportion) %>% unique()

# d_clean_main_collapsedCompetitor_summary %>% write_csv(., "d_clean_main_collapsedCompetitor_summary_100.csv")

d_clean_main_collapsedCompetitor_summary %>% 
  ggplot(aes(x = answerType, fill = answerType, y = responseCategory_proportion)) +
  geom_col() +
  facet_wrap( itemName ~ . , ncol = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(strip.text.x = element_text(size = 10)) +
  theme(panel.spacing = unit(2, "lines")) +
  ylab("Proportion of answer types collapsing competitors") +
  xlab("answer type")
  

# ggsave("viz/free_production_byAnswerOption_acrossCompetitor_100.pdf", width = 12, height = 28)
```

The second plot explores whether there is a qualitative difference when adding the exploratory "competitor/other" category -- this does not seem to be the case. 

```{r, echo=FALSE, fig.height=28, fig.width=12}
# plot by vignette
df_clean_main_summary  %>%
  ggplot(aes(x = answerType, fill = answerType, y = responseCategory_proportion)) +
  geom_col() +
  facet_wrap( itemName ~ . , ncol = 4) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(strip.text.x = element_text(size = 10)) +
  theme(panel.spacing = unit(2, "lines")) +
  ylab("Proportion of answer type") +
  xlab("answer type")

#ggsave("viz/free_production_byAnswerOption_100.pdf", width = 12, height = 28)
```

The plot below shows response proportions by response category averaged across vignettes. Again, including one competitor category vs two exploratory categories is compared.

```{r, echo=FALSE, fig.height=6, fig.width=8}
# plot answerTypes proportions averaged over items
df_answerOptions_global_summary <- df_clean_main %>% 
  group_by(answerType) %>% 
  summarise(answerType_count = n(), 
            answerType_proportion = answerType_count / nrow(df_clean_main)
            )
#sum(df_answerOptions_global_summary$answerType_proportion)
#df_answerOptions_global_summary

# collapsed across different competitor response types
df_answerOptions_acrossCompetitor_global_summary <- df_clean_main %>%
  mutate(answerType = ifelse(category == "competitor/other", "competitor", category),
         answerType = factor(answerType, levels = c('competitor', 'sameCategory', 'otherCategory', 'fullList', 'other', 'taciturn'))) %>% 
  group_by(answerType) %>% 
  summarise(answerType_count = n(), 
            answerType_proportion = answerType_count / nrow(df_clean_main)
            )
#sum(df_answerOptions_acrossCompetitor_global_summary$answerType_proportion)
#df_answerOptions_acrossCompetitor_global_summary

df_answerOptions_acrossCompetitor_global_summary %>%
  ggplot(aes(x = answerType, fill = answerType, y = answerType_proportion)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylab("Global proportion of answer type") +
  xlab("answer type")
#ggsave("viz/free_production_global_answerTypes_acrossCompetitor_100.pdf", width = 8, height = 6)

df_answerOptions_global_summary %>%
  ggplot(aes(x = answerType, fill = answerType, y = answerType_proportion)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylab("Global proportion of answer type") +
  xlab("answer type")
#ggsave("viz/free_production_global_answerTypes_100.pdf", width = 8, height = 6)

```

## Exploring weak vignettes and weird participant behavior


```{r, echo=FALSE}
# checking vignettes by number of competitor/other responses
cat("Vignettes receiving the most 'other' responses (mostly 'no but we have other options which might interest you')")
df_clean_main_summary %>% filter(answerType == "other") %>%
  arrange(desc(responseCategory_proportion)) %>% head()

cat("\nVignettes with highest proportion of competitor responses where either additional information was included or the named competitor differed from our preclassification")
df_clean_main_summary %>% filter(answerType == "competitor/other") %>%
  arrange(desc(responseCategory_proportion)) %>% head()

cat("\nVignettes receiving the most 'taciturn' responses")
df_clean_main_summary %>% filter(answerType == "taciturn") %>%
  arrange(desc(responseCategory_proportion)) %>% head()

```

```{r, echo=FALSE}
# by-subject exploration
bySubj_type_counts <- df_clean_main %>% distinct(submission_id, category) %>% 
  group_by(submission_id) %>%
  mutate(n_distinct_types = n())

cat("Number of participants providing taciturn responses only: ", bySubj_type_counts %>% arrange(n_distinct_types) %>% filter(category == "taciturn", n_distinct_types == 1) %>% nrow(.))

cat("\nNumber of participants providing competitor responses only: ", bySubj_type_counts %>% arrange(n_distinct_types) %>% filter(category == "competitor", n_distinct_types == 1) %>% nrow(.))

cat("\nNumber of participants providing 'other' responses only: ", bySubj_type_counts %>% arrange(n_distinct_types) %>% filter(category == "other", n_distinct_types == 1) %>% nrow(.))

cat("\nMaximal number of distinct response types provided by a participant: ", bySubj_type_counts %>% arrange(desc(n_distinct_types)) %>% .[1,] %>% .$n_distinct_types)
cat("\nNumber of participants providing maximal number of distinct response types: ", bySubj_type_counts %>% filter(n_distinct_types == 6) %>% pull(submission_id) %>% unique() %>% length())

cat("\nAverage number of response types provided by a participant: ", bySubj_type_counts %>%select(-category) %>% pull(n_distinct_types) %>% mean())
```

Visualize global distribution if participants producing "No" responses only would be excluded.
```{r, echo=FALSE}
df_clean_main <- df_clean_main %>% rowwise() %>% mutate(
  bad_response = gsub("\n", "", gsub(" ", "", tolower(answer))) == "no"
) 
#df_clean_main %>% filter(bad_response == TRUE)
## it seems that participants 307 and 347 only provded bad responses ('no')

df_clean_main %>% filter(!(submission_id %in% c(307, 347))) %>% 
  mutate(answerType = ifelse(category == "competitor/other", "competitor", category),
         answerType = factor(answerType, levels = c('competitor', 'sameCategory', 'otherCategory', 'fullList', 'other', 'taciturn'))) %>%
  group_by(answerType) %>% 
  summarise(answerType_count = n(), 
            answerType_proportion = answerType_count / nrow(df_clean_main)
            ) %>%
  ggplot(aes(x = answerType, fill = answerType, y = answerType_proportion)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylab("Global proportion of answer type") +
  xlab("answer type")
```

## Follow-up analyses

Below, analyses suggested during the meeting on Nov 10th are incorporated. 
First, the length (in terms of characters) of the anticipated competitor as well as averaged together with the same category alternatives is extracred. We check whether participants tended to produce more taciturn responses when the alternatives were longer.
```{r, echo=FALSE}
df_vignettes <- read_csv("..//trials/trials_split.csv") %>% 
  select(itemName, itemQuestion, competitor, sameCategory1, sameCategory2, otherCategory1, otherCategory2)
df_vignettes <- df_vignettes %>% 
  rowwise() %>%
  mutate(
  comp_length = nchar(competitor),
  sameCat_avg_length = (nchar(competitor) + nchar(sameCategory1) + nchar(sameCategory2) )/ 3
)  %>% select(itemName, comp_length, sameCat_avg_length)

# add to original df
d_clean_main_wVignette <- df_clean_main %>%
  left_join(., df_vignettes, by=c('itemName'))

d_clean_main_collapsedCompetitor_summary_wVignette <- d_clean_main_collapsedCompetitor_summary %>%
  left_join(., df_vignettes, by=c('itemName'))

lm_nchar_comp_prop <- lm(responseCategory_proportion ~ comp_length, data = d_clean_main_collapsedCompetitor_summary_wVignette %>% filter(answerType == "taciturn"))
summary(lm_nchar_comp_prop)

lm_nchar_sameCat_prop <- lm(responseCategory_proportion ~ sameCat_avg_length, data = d_clean_main_collapsedCompetitor_summary_wVignette %>% filter(answerType == "taciturn"))
summary(lm_nchar_sameCat_prop)
```

Further, order effects of the trials are investigated. We check if participants become lazy over the trials and are therefore more likely to produce taciturn responses towards the end of the experiment. This seems not to be the case. If anything, participants tended to produce slightly more taciturn responses in the beginning of the experiment.

```{r, fig.width = 6, fig.height = 8}
# collapse across items and participants, look at trial number
df_trialNum <- df_clean_main %>% 
  mutate(answerType = ifelse(category == "competitor/other", "competitor", category),
         answerType = factor(answerType, levels = c('competitor', 'sameCategory', 'otherCategory', 'fullList', 'other', 'taciturn'))) %>%
  group_by(submission_id) %>%
  mutate(trialNr_main = (1:n())) %>%
  ungroup() %>%
  group_by(answerType, trialNr_main) %>% 
  summarise(answerType_count = n(), 
            answerType_proportion = answerType_count / nrow(df_clean_main)
            ) 
df_trialNum %>%
  ggplot(aes(x = trialNr_main, fill = answerType, y = answerType_proportion)) +
  geom_col() +
  facet_wrap(answerType ~ ., ncol = 2) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylab("Global proportion of answer type") +
  xlab("Trial number")
```

```{r}
lm_orderEffect <- lm(answerType_proportion ~ trialNr_main, data = df_trialNum %>% filter(answerType == "taciturn"))
summary(lm_orderEffect)
```