---
title: "QA free typing analysis"
author: "Polina Tsvilodub"
date: '2023-01-02'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library(tidyverse)
library(tidyboot)
library(brms)
library(tidybayes)
library(ggpattern)
library(cspplot)
```

```{r, include=FALSE}
# these options help Stan run faster
options(mc.cores = parallel::detectCores())
```

## Intro


## Load processed experimental results and neural model data, display descriptions


```{r, include=FALSE, warning=FALSE, message=FALSE}
answerOrder <- c( 'competitor', 'sameCategory', 'otherCategory', 'fullList', 'taciturn', 'other')

e1_humans <- read_csv("data/results_QA-overinfo-freeTyping-cogsci_full_anonymized_categorized_cleaned.csv") %>% select(category, answer, itemName) %>%
  mutate(prompt = "human E1") %>% rename("predictions" = "answer")

e2_humans <- read_csv("../data_paper_neural/e2_human_summary_wide.csv") %>% 
  mutate(prompt = "human E2")
e2_humans_raw <- read_csv("../code/paper_data/e2_human_tidy.csv") %>% mutate(prompt = "human E2")
e2_human_byCategory <- read_csv("../code/paper_data/e2_human_category_raw.csv")
e2_human_byCategory_summary <- read_csv("../code/paper_data/e2_human_category_raw.csv") %>% group_by(category) %>%
  summarize(count = n(), prop = count / nrow(read_csv("../code/paper_data/e2_human_category_raw.csv") %>% group_by(category))) %>%
  mutate(prompt = "human E2")
e2_items_cats <- read_csv("../experiments/contextSensitive_free_production/trials/trials_split_cogsci_pilot4_ItemCategorization.csv") %>%
  select(-itemName, -itemQuestion)  
e2_vignettes <-  read_csv("../data_paper_neural/e2_vignettes.csv")


nm_samples_categorized_e1 <- read_csv("../data_paper_neural/QA_neural_models_categorized_samples_E1.csv") 
nm_samples_categorized_e2 <- read_csv("../data_paper_neural/QA_neural_models_categorized_samples_promptE2.csv")

lm_scores_byModel_summary_e1 <- read_csv("../data_paper_neural/e1_SA_model_probs.csv")
lm_scores_byModel_summary_e2 <- read_csv("../data_paper_neural/e2_SA_model_probs.csv")

e1_samples_global <- nm_samples_categorized_e1 %>%
  select(-probs, -is_few_shot, -dataset, -model_type) %>%
  rename("prompt" = "model_name") %>%
  rbind(., e1_humans)

e1_gpt3 <- read_csv("../data_paper_neural/e1_gpt3_byPrompt_raw.csv")
e1_gpt3_summary <- read_csv("../data_paper_neural/e1_gpt3_byPrompt_summary.csv")

e2_gpt3_category_summary <- read_csv("../data_paper_neural/e2_gpt3_byPrompt_byCategory_summary.csv")
e2_gpt3_category <- read_csv("../data_paper_neural/e2_gpt3_byPrompt_byCategory_raw.csv")
e2_gpt3_context_summary <- read_csv("../data_paper_neural/e2_gpt3_byPrompt_byContext_summary.csv")

e2_samples_global <- nm_samples_categorized_e2 %>% select(-probs, -is_few_shot, -dataset, -model_type) %>%
  rename("prompt" = "model_name") %>%
  rbind(., e2_human_byCategory %>% select(-submission_id, -settingName, -response_option) %>% mutate(prompt = "human E2") %>% rename("predictions" = "answer"))


e2_gpt3_context_raw <- read_csv("../data_paper_neural/e2_gpt3_byPrompt_byCategory_raw.csv") %>%
  group_by(prompt, context_nr) %>%
  mutate(prompt_context_count = n()) %>% ungroup() %>%
  group_by(prompt, itemName) %>%
  mutate(prompt_item_count = n()) %>% ungroup() %>%
  separate_rows(response_option, sep=",") %>%
  mutate(response_option = gsub(" ", "", response_option)) %>%
  left_join(., e2_items_cats, by = c("settingName", "response_option") ) %>% select(-context2_category, -context1_category, -probs)
```

```{r, echo=FALSE}
cat("Models that were used: ", nm_samples_categorized %>% pull(model_name) %>% unique())
cat("Number of models that were used: ", nm_samples_categorized %>% pull(model_name) %>% unique() %>% length())


df_samples_byModel_byContext_summary_e1 <- nm_samples_categorized_e1 %>% group_by(model_name, is_few_shot, category) %>%
  summarize(n = n()) %>%
  mutate(prop = n / sum(n))
cat("Proportion of response categories by model: ")
df_samples_byModel_byContext_summary_e1

cat("Proportion of 'yes' response categories by model (sorted from worst model to best): ")
df_samples_byModel_byContext_summary_e1 %>% filter(category == 'yes') %>% arrange(desc(prop))

cat("Proportion of 'taciturn' response categories by QA model (sorted from worst model to best): ")
df_samples_byModel_byContext_summary_e1 %>% filter(category == 'taciturn') %>% arrange(desc(prop))

df_samples_byModel_byContext_summary_e1 <- nm_samples_categorized_e1 %>% 
  filter((category != 'yes') ) %>%
  group_by(model_name, is_few_shot, category) %>%
  summarize(n = n()) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(answerType = factor(category, levels=answerOrder))

df_samples_byModel_summary_e1 <- nm_samples_categorized_e1 %>% 
  filter((category != 'yes')) %>%
  group_by(model_name, category) %>%
  summarize(n = n(), mean_probs = mean(probs)) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(answerType = factor(category, levels=answerOrder))

df_samples_byModelType_summary_e1 <- nm_samples_categorized %>% 
  filter((category != 'yes')) %>%
  group_by(model_type, category) %>%
  summarize(n = n(), mean_probs = mean(probs)) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(answerType = factor(category, levels=answerOrder))


df_samples_global_summary_e1 <- nm_samples_categorized_e1 %>%
  filter((category != 'yes')) %>%
  group_by(category) %>%
  summarize(n = n()) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(answerType = factor(category, levels=answerOrder))
cat("Global response category proportions:")
df_samples_global_summary_e1
```

```{r, echo=FALSE}
cat("Models that were used: ", nm_samples_categorized_e2 %>% pull(model_name) %>% unique())
cat("Number of models that were used: ", nm_samples_categorized_e2 %>% pull(model_name) %>% unique() %>% length())


df_samples_byModel_byContext_summary_e2 <- nm_samples_categorized_e2 %>% group_by(model_name, is_few_shot, category) %>%
  summarize(n = n()) %>%
  mutate(prop = n / sum(n))
cat("Proportion of response categories by model: ")
df_samples_byModel_byContext_summary_e2

cat("Proportion of 'yes' response categories by model (sorted from worst model to best): ")
df_samples_byModel_byContext_summary_e2 %>% filter(category == 'yes') %>% arrange(desc(prop))

cat("Proportion of 'taciturn' response categories by QA model (sorted from worst model to best): ")
df_samples_byModel_byContext_summary_e2 %>% filter(category == 'taciturn') %>% arrange(desc(prop))

df_samples_byModel_byContext_summary_e2 <- nm_samples_categorized_e2 %>% 
  filter((category != 'yes') ) %>%
  group_by(model_name, is_few_shot, category) %>%
  summarize(n = n()) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(answerType = factor(category, levels=answerOrder))

df_samples_byModel_summary_e2 <- nm_samples_categorized_e2 %>% 
  filter((category != 'yes')) %>%
  group_by(model_name, category) %>%
  summarize(n = n(), mean_probs = mean(probs)) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(answerType = factor(category, levels=answerOrder))

df_samples_byModelType_summary_e2 <- nm_samples_categorized_e2 %>% 
  filter((category != 'yes')) %>%
  group_by(model_type, category) %>%
  summarize(n = n(), mean_probs = mean(probs)) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(answerType = factor(category, levels=answerOrder))


df_samples_global_summary_e2 <- nm_samples_categorized_e2 %>%
  filter((category != 'yes')) %>%
  group_by(category) %>%
  summarize(n = n()) %>%
  mutate(prop = n / sum(n)) %>%
  mutate(answerType = factor(category, levels=answerOrder))
cat("Global response category proportions:")
df_samples_global_summary_e2

df_samples_byModel_summary_e2 %>% View()
```

### Comparing neural and human responses

```{r}
df_samples_byModel_summary_e1 %>% View()
# retrieve ChatGPT by context results

nm_samples_categorized_e1 %>% filter(model_name == "chatGPT") %>%
  filter((category != 'yes')) %>%
  group_by(model_name, category, is_few_shot) %>%
  mutate(n = n()) %>% ungroup() %>% group_by(is_few_shot) %>%
  mutate(cat_n = n(),
    prop = n / cat_n) %>%
  select(model_name, is_few_shot, category, prop) %>% unique()

nm_samples_categorized_e2 %>% filter(model_name == "chatGPT") %>%
  filter((category != 'yes')) %>%
  group_by(model_name, category, is_few_shot) %>%
  mutate(n = n()) %>% ungroup() %>% group_by(is_few_shot) %>%
  mutate(cat_n = n(),
    prop = n / cat_n) %>%
  select(model_name, is_few_shot, category, prop) %>% unique()
```

```{r}
e2_gpt3_context_summary %>% 
  mutate(global_category = factor(global_category, levels = c( 'otherCategory', 'mostSimilar', 'competitor_c2', 'competitor_c1'),
                           labels = c("unrelated option\n(carpet)", "a priori\nsimilar (pillow)", "competitor 2\n(bubble wrap)", "competitor 1\n(sleeping bag)")
                           )) %>%
  ggplot(., aes(fill = prompt, x = global_category)) +
  geom_col(aes(y = context1), position = position_dodge(preserve = "single"), color = "#575463" ) +
  geom_col(aes(y = -context2), position = position_dodge(preserve = "single"), color = "#575463" ) +
  theme_csp() + 
  theme( axis.text.y = element_text(size = 12), axis.text.x = element_text(size = 12),  legend.title = element_text(size=12), legend.text = element_text(size=12), legend.position = "right", plot.title = element_text(hjust = 0.5)) + # , axis.ticks.y = element_blank(), 
  scale_y_continuous( limits = c(-1, 1), breaks = c(-1, -0.5, 0, 0.5, 1), labels = c("1", "0.5", "0", "0.5", "1")) +
  geom_hline(yintercept = 0, color = "white", size = 1) +
  coord_flip() +
  ylab("mirror transport <--> sleepover") +
  xlab("") +
  ggtitle("Do you have a blanket?")


#ggsave("viz/e2_byPrompt_vertical_e2Prompts_fixed.pdf", width = 6.5, height = 4 )
```

### Model probabilities

Below, the scores assigned to provided answer types are compared to the proportions of those answer types generated by the language models during sampling. Whenever the responses sampled from the model were difficult to classify due to half-generated phrases (like "kick" instead of kickboxing), they were categorized as "other" responses. 
The comparison is by model type. 


Next, probabilities computed for single response options are compared to average probabilities computed over all permutations of alternatives in the response sentences and generation proportions.

```{r, echo=FALSE}
df_samples_byModel_byContext_gpt3 <- df_samples_byModel_byContext_summary %>% filter(model_name == "gpt3-davinci-003") %>% 
  mutate(model_name = ifelse(is_few_shot == TRUE, "gpt3_oneShot", "gpt3_zeroShot"))

df_samples_byModel_summary_forComp <- df_samples_byModel_summary %>% ungroup() %>%
  filter(model_name != "gpt3-davinci-003") %>%
           #   mutate(model_name = ifelse(model_name == "gpt3-davinci-003", "gpt3_oneShot", model_name)) %>%
              select(model_name, answerType, prop) %>% #filter(answerType != "other") %>%
  rbind(., df_samples_byModel_byContext_gpt3 %>% ungroup() %>% select(model_name, answerType, prop))

df_samples_byModel_summary_forComp <- df_samples_byModel_summary_forComp %>% group_by(model_name) %>%
  mutate(propSum = sum(prop),
         prop = prop / propSum
         ) %>% ungroup()

lm_scores_byModel_wProduction <- lm_scores_byModel %>%
  left_join(., df_samples_byModel_summary_forComp,
            by = c("model_name", "answerType")
            ) %>%
  mutate(prop = ifelse(is.na(prop), 0, prop)) %>%
  left_join(., df_human_global %>% mutate(human_prop = prop) %>% select(-model_name, -prop), by = "answerType")

```


For the paper, we average the results from short and long response probs and compare them to the models' sample proportions and human performance:
```{r, echo=FALSE, fig.width=16, fig.height=15}
lm_scores_short_summary <- lm_scores_short %>% 
  mutate(answer_type_length_norm_prob_short = ifelse(is.na(answer_type_length_norm_prob_short), 0, answer_type_length_norm_prob_short)) %>%
  group_by(model_name, answerType) %>%
  summarize(answer_type_prob_avg_short = mean(answer_type_prob_avg_short),
            answer_type_length_norm_prob_short = mean(answer_type_length_norm_prob_short),
            answer_type_ppl_short = mean(answer_type_ppl_short)
            ) 

lm_scores_byModel_wProduction_wShort <- lm_scores_byModel_wProduction %>%
  left_join(., lm_scores_short_summary, by = c("model_name", "answerType"))

lm_scores_byModel_wProduction_avg <- lm_scores_byModel_wProduction_wShort %>% 
  filter(!(is.na(answer_type_prob_avg))) %>%
  mutate(answer_type_avg = (answer_type_prob_avg + answer_type_prob_avg_short)/2,
         answerType = factor(answerType, levels=c("competitor","sameCategory", "otherCategory", "fullList", "other", "taciturn"))
         ) 
```

A comparison of human data against average probabilities / samples proportions of the models across models is shown below:
```{r, echo=FALSE, fig.height=4, fig.width=6}
lm_scores_byModel_wProduction_avg_summary <- lm_scores_byModel_wProduction_avg %>% 
  mutate(model_name = "model_prob") %>%
  group_by(answerType, model_name) %>%
  summarize(prop = mean(answer_type_avg))

```



## Stats

Compute p-value of human data under model data: Chi-square tests of human response proportions vs model probabilities and response proportions (assumed to be ground truth).

```{r, warning=FALSE, message=FALSE}
e1_samples_global <- e1_samples_global %>% mutate(
  category = factor(category, levels = c("competitor", "sameCategory", "otherCategory", "fullList", "other", "taciturn"))
)
e1_samples_global_model_summary <- e1_samples_global %>% filter(prompt != "human E1") %>%
  group_by(prompt) %>% mutate(resp_count = n()) %>% group_by(prompt, category) %>% summarise(cat_count = n(), prop = cat_count / resp_count) %>% unique()
# assumed order of counts / proportions: comp, sameCat, otherCat, fullList, other, taciturn
human_counts_e1 <- e1_samples_global %>% filter(prompt == "human E1") %>% group_by(category) %>%
  summarize(count = n()) 

e1_gpt3_summary_pval <- e1_gpt3_summary %>% filter(prompt != "human E1") %>% 
  mutate(category = factor(category, levels = c("competitor", "sameCategory", "otherCategory", "fullList", "other", "taciturn")))

compute_p <- function(human_counts, name, models_df, type) {
  cats <- c("competitor", "sameCategory", "otherCategory", "fullList", "other", "taciturn")
  
  if (type == "samples") {
    df <- models_df %>% filter(prompt == name) %>% select(category, prop) 
  } else {
    df <- models_df %>% filter(prompt == name) %>% select(category, answer_type_prob) %>%
      rename("prop" = "answer_type_prob") 
  }
  df <- df %>% filter(!is.na(category))
  answer_types <- df$category
  # pad missing category with epsilon and renormalize
  if (answer_types %>% length() < 6) {
    for (a in setdiff(cats, answer_types)) {
      df <- df %>% ungroup() %>%
      add_row(category = a, prop = 0.01)
    }
  }
  df <- df %>% ungroup() %>% mutate(
        category = factor(category, levels = c("competitor", "sameCategory", "otherCategory", "fullList", "other", "taciturn")),
        sum_prop = sum(prop),
        prop = prop / sum_prop
      )  #%>% filter(!is.na(category))
  df <- human_counts %>% left_join(., df, by = "category")
  print(df)
  print(df %>% pull(count))
  print(df %>% pull(prop))
  res <- chisq.test(x = df %>% pull(count), p = df %>% pull(prop), rescale.p = TRUE)
  return(res$p.value)
}

all_models_samples_e1 <- e1_samples_global_model_summary %>% pull(prompt) %>% unique()
# define df 
df_pvals_models_vs_humans_e1 <- data.frame(model_name=character(), type=character(), p=double())
# iterate over model samples
for (m in all_models_samples_e1) {
  print(m)
  p <- compute_p(human_counts_e1, m, e1_samples_global_model_summary, "samples")
  df_pvals_models_vs_humans_e1 <- df_pvals_models_vs_humans_e1 %>%
    add_row(model_name=m, type="samples", p=p)
}
# iterate over scores
all_gpt3_models <- e1_gpt3_summary_pval %>% pull(prompt) %>% unique()
for (m in all_gpt3_models) {
  p <- compute_p(human_counts_e1, m, e1_gpt3_summary_pval, "samples")
  df_pvals_models_vs_humans_e1 <- df_pvals_models_vs_humans_e1 %>%
    add_row(model_name=m, type="prob", p=p)
}
cat("P values under Chi square tests of human data against probabilities / sample proportions of neural models ")
df_pvals_models_vs_humans_e1
```

```{r}
all(df_pvals_models_vs_humans_e1 %>% pull(p) < 0.05)
```

Pull the supplementary table for E1:
```{r}
e1_humans_summary <- e1_humans %>% group_by(category) %>%
  summarise(n = n()) %>%
  mutate(human_prop = n / sum(n))

e1_samples_global_model_summary_wHuman <- e1_samples_global_model_summary %>% full_join(., e1_humans_summary, by = c("category")) %>%
  select(-n, -cat_count) %>%
  mutate(byCat_diff = human_prop - prop) 

e1_samples_global_model_summary_wHuman_wide <- e1_samples_global_model_summary_wHuman %>% filter(!is.na(category)) %>% select(-prop, -human_prop) %>% 
  pivot_wider(names_from = "category", values_from = "byCat_diff") %>%
  mutate(competitor = ifelse(is.na(competitor), e1_humans_summary %>% filter(category == "competitor") %>% pull(human_prop), competitor),
         sameCategory = ifelse(is.na(sameCategory), e1_humans_summary %>% filter(category == "sameCategory") %>% pull(human_prop), sameCategory),
         otherCategory = ifelse(is.na(otherCategory), e1_humans_summary %>% filter(category == "otherCategory") %>% pull(human_prop), otherCategory),
         fullList = ifelse(is.na(fullList), e1_humans_summary %>% filter(category == "fullList") %>% pull(human_prop), fullList),
         other = ifelse(is.na(other), e1_humans_summary %>% filter(category == "other") %>% pull(human_prop), other),
         taciturn = ifelse(is.na(taciturn), e1_humans_summary %>% filter(category == "taciturn") %>% pull(human_prop), taciturn)
         ) %>%
  mutate(aboslute_diff = mean(c(abs(competitor), abs(sameCategory), abs(fullList), abs(other), abs(taciturn), abs(otherCategory))))

#e1_samples_global_model_summary_wHuman_wide %>% write_csv("../code/paper_data/e1_SA_model_proportions.csv")

lm_scores_byModel_summary_e1_wHuman <- lm_scores_byModel_summary_e1 %>% rename("category" = "answer_type") %>% 
  full_join(., e1_humans_summary %>% filter(category != "other"), by = c("category")) %>%
  select(-n) %>%
  mutate(byCat_diff = human_prop - answer_type_avg) %>% select(-answer_type_avg, -human_prop) %>%
  pivot_wider(names_from = "category", values_from = "byCat_diff") %>%
  mutate(competitor = ifelse(is.na(competitor), e1_humans_summary %>% filter(category == "competitor") %>% pull(human_prop), competitor),
         sameCategory = ifelse(is.na(sameCategory), e1_humans_summary %>% filter(category == "sameCategory") %>% pull(human_prop), sameCategory),
         otherCategory = ifelse(is.na(otherCategory), e1_humans_summary %>% filter(category == "otherCategory") %>% pull(human_prop), otherCategory),
         fullList = ifelse(is.na(fullList), e1_humans_summary %>% filter(category == "fullList") %>% pull(human_prop), fullList),
         taciturn = ifelse(is.na(taciturn), e1_humans_summary %>% filter(category == "taciturn") %>% pull(human_prop), taciturn)
         ) %>%
  mutate(aboslute_diff = mean(c(abs(competitor), abs(sameCategory), abs(fullList), abs(taciturn), abs(otherCategory))))

#lm_scores_byModel_summary_e1_wHuman %>% write_csv("../code/paper_data/e1_model_probs.csv")

```

GPT-3 probs for E1:
```{r}
oneShot_long_e1 <- read_csv("../code/gpt3_data/experiment1/probs/oneShot/GPT3-davinci-003-predictions-overinfo-oneShotLearer-cogsci.csv") 
oneShot_short_e1 <- read_csv("../code/gpt3_data/experiment1/probs/oneShot/GPT3-davinci-003-predictions-overinfo-oneShotLearner-cogsci_shortPrompts_long.csv") 

oneShot_long_e1_long <- oneShot_long_e1 %>% pivot_longer(names_to = "category", cols = -itemName, values_to = "prob_long" )

oneShot_short_e1_long <- oneShot_short_e1 %>% select(itemName, answer_type, answer_type_prob_avg) %>% rename("category" = "answer_type", "prob_short" = "answer_type_prob_avg")

oeShot_e1_gpt3_probs <- left_join(oneShot_long_e1_long, oneShot_short_e1_long, by = c("itemName", "category")) %>% 
  mutate(
    prob_short = ifelse(is.na(prob_short), 0, prob_long),
    avg_prob = (prob_long + prob_short)/2) %>%
  group_by(category) %>%
  summarize( mean_prob = mean(avg_prob))

oeShot_e1_gpt3_probs_wHuman <- oeShot_e1_gpt3_probs %>% full_join(., e1_humans_summary %>% filter(category != "other"), by = c("category")) %>%
  mutate(diff = human_prop - mean_prob) %>%
  select(-n, -mean_prob, -human_prop) %>%
  pivot_wider(names_from = "category", values_from = "diff") %>% 
  mutate(model = "GPT-3 one-shot CoT E1",
         abs_diff = mean(c(abs(competitor), abs(sameCategory), abs(fullList), abs(taciturn), abs(otherCategory)))
         )


zeroShot_long_e1 <- read_csv("../code/gpt3_data/experiment1/probs/zeroShot/trials_LLMs_GPT3-davinci-003-predictions-overinfo-zeroShotLearer-cogsci-long_prob.csv") %>% mutate(answer_type = rep(c('taciturn', 'competitor', 'sameCategory', 'otherCategory', 'fullList'), 30)) %>% 
  select(itemName, answer_type, answer_type_prob_avg) %>% rename("category" = "answer_type", "prob_long" = "answer_type_prob_avg")
zeroShot_short_e1 <- read_csv("../code/gpt3_data/experiment1/probs/zeroShot/GPT3-davinci-003-predictions-overinfo-zeroShotLearer-cogsci-shortPrompts-long.csv") %>% select(itemName, answer_type, answer_type_prob_avg) %>% rename("category" = "answer_type", "prob_short" = "answer_type_prob_avg")


zeroShot_e1_gpt3_probs <- left_join(zeroShot_long_e1, zeroShot_short_e1, by = c("itemName", "category")) %>% 
  mutate(
    prob_short = ifelse(is.na(prob_short), 0, prob_long),
    avg_prob = (prob_long + prob_short)/2) %>%
  group_by(category) %>%
  summarize( mean_prob = mean(avg_prob))

zeroShot_e1_gpt3_probs_wHuman <- zeroShot_e1_gpt3_probs %>% full_join(., e1_humans_summary %>% filter(category != "other"), by = c("category")) %>%
  mutate(diff = human_prop - mean_prob) %>%
  select(-n, -mean_prob, -human_prop) %>%
  pivot_wider(names_from = "category", values_from = "diff") %>% 
  mutate(model = "GPT-3 zero-shot CoT E1",
         abs_diff = mean(c(abs(competitor), abs(sameCategory), abs(fullList), abs(taciturn), abs(otherCategory)))
         )

e1_gpt3_probs <- rbind(oeShot_e1_gpt3_probs_wHuman, zeroShot_e1_gpt3_probs_wHuman)
#e1_gpt3_probs %>% write_csv("../code/paper_data/e1_SA_gpt3_probs.csv")

oneShot_long_e2 <- read_csv("../code/gpt3_data/experiment2/oneShot/GPT3-davinci-003-predictions-overinfo-oneShotLearner-cogsci-pilot4-e2CoT_long.csv") %>%
  rename("category" = "answer_type", "prob_long" = "answer_type_prob_avg")
oneShot_short_e2 <- read_csv("../code/gpt3_data/experiment2/oneShot/GPT3-davinci-003-predictions-overinfo-oneShotLearner-cogsci-pilot4-e2_short.csv") %>%
  rename("category" = "answer_type", "prob_short" = "answer_type_prob_avg")

oneShot_e2_gpt3_probs <- left_join(oneShot_long_e2, oneShot_short_e2, by = c("itemName", "category")) %>% 
  mutate(
    prob_short = ifelse(is.na(prob_short), 0, prob_long),
    avg_prob = (prob_long + prob_short)/2) %>%
  group_by(category) %>%
  summarize( mean_prob = mean(avg_prob))

oneShot_e2_gpt3_probs_wHuman <- oneShot_e2_gpt3_probs %>% full_join(., e2_human_byCategory_summary_human %>% filter(category != "other"), by = c("category")) %>%
  mutate(diff = human_prop - mean_prob) %>%
  select(-mean_prob, -human_prop) %>%
  pivot_wider(names_from = "category", values_from = "diff") %>% 
  mutate(model = "GPT-3 one-shot CoT E2",
         abs_diff = mean(c(abs(competitor), abs(sameCategory), abs(fullList), abs(taciturn), abs(otherCategory)))
         )

zeroShot_long_e2 <- read_csv("../code/gpt3_data/experiment2/zeroShot/GPT3-davinci-003-predictions-overinfo-zeroShotLearner-pilot4-long.csv") %>% 
  select(itemName, answer_type, answer_type_prob_avg) %>% rename("category" = "answer_type", "prob_long" = "answer_type_prob_avg")
zeroShot_short_e2 <- read_csv("../code/gpt3_data/experiment2/zeroShot/GPT3-davinci-003-predictions-overinfo-zeroShotLearner-cogsci-e2_short.csv") %>% 
  select(itemName, answer_type, answer_type_prob_avg) %>% rename("category" = "answer_type", "prob_short" = "answer_type_prob_avg")

zeroShot_e2_gpt3_probs <- left_join(zeroShot_long_e2, zeroShot_short_e2, by = c("itemName", "category")) %>% 
  mutate(
    prob_short = ifelse(is.na(prob_short), 0, prob_long),
    avg_prob = (prob_long + prob_short)/2) %>%
  group_by(category) %>%
  summarize( mean_prob = mean(avg_prob))

zeroShot_e2_gpt3_probs_wHuman <- zeroShot_e2_gpt3_probs %>% full_join(., e2_human_byCategory_summary_human %>% filter(category != "other"), by = c("category")) %>%
  mutate(diff = human_prop - mean_prob) %>%
  select(-mean_prob, -human_prop) %>%
  pivot_wider(names_from = "category", values_from = "diff") %>% 
  mutate(model = "GPT-3 zero-shot CoT E2",
         abs_diff = mean(c(abs(competitor), abs(sameCategory), abs(fullList), abs(mostSimilar), abs(taciturn), abs(otherCategory)))
         )
e2_gpt3_probs <- rbind(oneShot_e2_gpt3_probs_wHuman, zeroShot_e2_gpt3_probs_wHuman)
#e2_gpt3_probs %>% write_csv("../code/paper_data/e2_SA_gpt3_probs.csv")
```

The same exercise for E2:
```{r, warning=FALSE, message=FALSE}
e2_samples_global <- e2_samples_global %>% mutate(
  category = factor(category, levels = c("competitor", "mostSimilar", "sameCategory", "otherCategory", "fullList", "other", "taciturn"))
) 
e2_samples_global_model_summary <- e2_samples_global %>% filter(prompt != "human E2") %>% filter(!is.na(category)) %>%
  group_by(prompt) %>% mutate(resp_count = n()) %>% group_by(prompt, category) %>% summarise(cat_count = n(), prop = cat_count / resp_count) %>% unique()
# assumed order of counts / proportions: comp, sameCat, otherCat, fullList, other, taciturn
human_counts_e2 <- e2_samples_global %>% filter(prompt == "human E2") %>% group_by(category) %>%
  summarize(count = n()) 

e2_gpt3_summary_pval <- e2_gpt3_category_summary %>% filter(prompt != "human E2") %>% 
  mutate(category = factor(category, levels = c("competitor", "mostSimilar", "sameCategory", "otherCategory", "fullList", "other", "taciturn")))

compute_p <- function(human_counts, name, models_df, type) {
  cats <- c("competitor", "mostSimilar", "sameCategory", "otherCategory", "fullList", "other", "taciturn")
  
  if (type == "samples") {
    df <- models_df %>% filter(prompt == name) %>% select(category, prop) 
  } else {
    df <- models_df %>% filter(prompt == name) %>% select(category, answer_type_prob) %>%
      rename("prop" = "answer_type_prob") 
  }
  df <- df %>% filter(!is.na(category))
  answer_types <- df$category
  # pad missing category with epsilon and renormalize
  if (answer_types %>% length() < 7) {
    for (a in setdiff(cats, answer_types)) {
      df <- df %>% ungroup() %>%
      add_row(category = a, prop = 0.01)
    }
  }
  df <- df %>% ungroup() %>% mutate(
        category = factor(category, levels = c("competitor", "mostSimilar", "sameCategory", "otherCategory", "fullList", "other", "taciturn")),
        sum_prop = sum(prop),
        prop = prop / sum_prop
      )  #%>% filter(!is.na(category))
  df <- human_counts %>% left_join(., df, by = "category")
  print(df)
  print(df %>% pull(count))
  print(df %>% pull(prop))
  res <- chisq.test(x = df %>% pull(count), p = df %>% pull(prop), rescale.p = TRUE)
  return(res$p.value)
}

all_models_samples_e2 <- e2_samples_global_model_summary %>% pull(prompt) %>% unique()
# define df 
df_pvals_models_vs_humans_e2 <- data.frame(model_name=character(), type=character(), p=double())
# iterate over model samples
for (m in all_models_samples_e2) {
  print(m)
  p <- compute_p(human_counts_e2, m, e2_samples_global_model_summary, "samples")
  df_pvals_models_vs_humans_e2 <- df_pvals_models_vs_humans_e2 %>%
    add_row(model_name=m, type="samples", p=p)
}
# iterate over scores
all_gpt3_models_e2 <- e2_gpt3_summary_pval %>% pull(prompt) %>% unique()
for (m in all_gpt3_models_e2) {
  p <- compute_p(human_counts_e2, m, e2_gpt3_summary_pval, "samples")
  df_pvals_models_vs_humans_e2 <- df_pvals_models_vs_humans_e2 %>%
    add_row(model_name=m, type="samples", p=p)
}
cat("P values under Chi square tests of human data against probabilities / sample proportions of neural models ")
df_pvals_models_vs_humans_e2
```

```{r}
all(df_pvals_models_vs_humans_e2 %>% pull(p) < 0.05)
```

Pull the supplementary table for E2:
```{r}
e2_human_byCategory_summary_human <-e2_human_byCategory_summary %>% rename("human_prop" = "prop") %>% select(-prompt, -count)

e2_samples_global_model_summary_wHuman <- e2_samples_global_model_summary %>% full_join(., e2_human_byCategory_summary_human, by = c("category")) %>%
  select(-cat_count) %>%
  mutate(byCat_diff = human_prop - prop)  %>% ungroup()

e2_samples_global_model_summary_wHuman_wide <- e2_samples_global_model_summary_wHuman %>% filter(!is.na(category)) %>% select(-prop, -human_prop) %>% 
  pivot_wider(names_from = "category", values_from = "byCat_diff") %>%
  mutate(competitor = ifelse(is.na(competitor), e2_human_byCategory_summary_human %>% filter(category == "competitor") %>% pull(human_prop), competitor),
         sameCategory = ifelse(is.na(sameCategory), e2_human_byCategory_summary_human %>% filter(category == "sameCategory") %>% pull(human_prop), sameCategory),
         otherCategory = ifelse(is.na(otherCategory), e2_human_byCategory_summary_human %>% filter(category == "otherCategory") %>% pull(human_prop), otherCategory),
         fullList = ifelse(is.na(fullList), e2_human_byCategory_summary_human %>% filter(category == "fullList") %>% pull(human_prop), fullList),
         other = ifelse(is.na(other), e2_human_byCategory_summary_human %>% filter(category == "other") %>% pull(human_prop), other),
         taciturn = ifelse(is.na(taciturn), e2_human_byCategory_summary_human %>% filter(category == "taciturn") %>% pull(human_prop), taciturn),
         mostSimilar = ifelse(is.na(mostSimilar), e2_human_byCategory_summary_human %>% filter(category == "mostSimilar") %>% pull(human_prop), mostSimilar)
         ) %>%
  rowwise() %>%
  mutate(aboslute_diff = mean(c(abs(competitor), abs(sameCategory), abs(fullList), abs(other), abs(taciturn), abs(otherCategory), abs(mostSimilar))))

#e2_samples_global_model_summary_wHuman_wide %>% write_csv("../code/paper_data/e2_SA_model_proportions.csv")


lm_scores_byModel_summary_e2_wHuman <- lm_scores_byModel_summary_e2 %>% rename("category" = "answer_type") %>% 
  full_join(., e2_human_byCategory_summary_human %>% filter(category != "other"), by = c("category")) %>%
  mutate(byCat_diff = human_prop - answer_type_avg) %>% select(-answer_type_avg, -human_prop) %>%
  pivot_wider(names_from = "category", values_from = "byCat_diff") %>%
  mutate(competitor = ifelse(is.na(competitor), e2_human_byCategory_summary_human %>% filter(category == "competitor") %>% pull(human_prop), competitor),
         sameCategory = ifelse(is.na(sameCategory), e2_human_byCategory_summary_human %>% filter(category == "sameCategory") %>% pull(human_prop), sameCategory),
         otherCategory = ifelse(is.na(otherCategory), e2_human_byCategory_summary_human %>% filter(category == "otherCategory") %>% pull(human_prop), otherCategory),
         fullList = ifelse(is.na(fullList), e2_human_byCategory_summary_human %>% filter(category == "fullList") %>% pull(human_prop), fullList),
         taciturn = ifelse(is.na(taciturn), e2_human_byCategory_summary_human %>% filter(category == "taciturn") %>% pull(human_prop), taciturn),
         mostSimilar = ifelse(is.na(mostSimilar), e2_human_byCategory_summary_human %>% filter(category == "mostSimilar") %>% pull(human_prop), mostSimilar)
         ) %>%
  mutate(aboslute_diff = mean(c(abs(competitor), abs(sameCategory), abs(fullList), abs(taciturn), abs(otherCategory), abs(mostSimilar))))

#lm_scores_byModel_summary_e2_wHuman %>% write_csv("../code/paper_data/e2_SA_model_probs.csv")
```

Pull E2 data under E1 prompts for SA
```{r}
e2_e1_CoT <- read_csv("../code/results/prompts/oneShotCoT_old_sanity-check/experiment2/GPT3-davinci-003-samples-oneShotLearner-n5-m64-cogsci-e2_categorized.csv") %>% 
  mutate(context_nr = rep(c("context1","context1","context1","context1","context1", "context2","context2","context2","context2","context2"), 13)) %>%
  filter(!is.na(category) & (category!="yes")) 

e2_e1_CoT_summary <- e2_e1_CoT %>% mutate(response_count = nrow(e2_e1_CoT)) %>% group_by(category) %>%
  summarize(prop = n()/ response_count) %>% unique() %>% pivot_wider(values_from = "prop", names_from = "category") %>%
  mutate(prompt = "E1 CoT prompt for E2")

e2_e1_QA <- read_csv("../code/results/prompts/oneShotExample/experiment2/GPT3-davinci-003-samples-oneShotLearner-n5-m64-cogci_categorized.csv") %>% 
  mutate(context_nr = rep(c("context1","context1","context1","context1","context1", "context2","context2","context2","context2","context2"), 13)) %>%
  filter(!is.na(category) & (category!="yes")) 

e2_e1_QA_summary <- e2_e1_QA %>% mutate(response_count = nrow(e2_e1_QA)) %>% group_by(category) %>%
  summarize(prop = n()/ response_count) %>% unique() %>% pivot_wider(values_from = "prop", names_from = "category") %>%
  mutate(otherCategory = 0, prompt = "E1 QA prompt for E2")

e2_e1_Explain <- read_csv("../code/results/prompts/oneShotExplanation/experiment2/GPT3-davinci-003-samples-oneShotLearner-n5-m64-cogsci-e2_categorized.csv") %>% 
  mutate(context_nr = rep(c("context1","context1","context1","context1","context1", "context2","context2","context2","context2","context2"), 13)) %>%
  filter(!is.na(category) & (category!="yes")) 

e2_e1_Explain_summary <- e2_e1_Explain %>% mutate(response_count = nrow(e2_e1_Explain)) %>% group_by(category) %>%
  summarize(prop = n()/ response_count) %>% unique() %>% pivot_wider(values_from = "prop", names_from = "category") %>%
  mutate(otherCategory = 0, prompt = "E1 explanation prompt for E2")

e2_e1_summary <- rbind(e2_e1_CoT_summary, e2_e1_QA_summary, e2_e1_Explain_summary)
#e2_e1_summary %>% write_csv("../code/paper_data/e2_SA_gpt3_onE1prompt.csv")
```

```{r}
e2_gpt3_context_global_cat_count <- e2_gpt3_context_raw %>% 
  group_by(context_nr, prompt, global_category) %>% mutate(count_cat = n()) %>% 
  ungroup() %>%
  rowwise() %>% 
  mutate(cat_cont_proportion = count_cat / prompt_context_count) %>%
  select(prompt, context_nr, global_category, cat_cont_proportion) %>% unique()

e2_gpt3_context_global_cat_count_wide <- e2_gpt3_context_global_cat_count %>%
  pivot_wider(names_from = "context_nr", values_from = "cat_cont_proportion")

e2_gpt3_context_global_cat_count_wide %>% filter(prompt == "one-shot CoT")


e2_gpt3_context_global_byVignette <- e2_gpt3_context_raw %>% 
  group_by(prompt, itemName) %>%
  mutate(vignette_count = n()) %>% ungroup() %>%
  group_by(prompt, global_category, itemName) %>%
  mutate(responseCategory_count = n()) %>% ungroup() %>% 
  mutate(subjMention_prop = responseCategory_count / vignette_count) %>%
  group_by(prompt, context_nr, global_category) %>%
  mutate(response_prop = mean(subjMention_prop)
         ) %>% select(prompt, settingName, context_nr, global_category, response_prop) %>%
  unique() %>%
  pivot_wider(values_from = response_prop, names_from = context_nr) %>%
  mutate(context1 = ifelse(is.na(context1), 0, context1),
         context2 = ifelse(is.na(context2), 0, context2)
         ) %>% group_by(prompt, global_category) %>%
  mutate(mean_context1 = mean(context1),
         mean_context2 = mean(context2)) %>% select(-settingName, -context1, -context2) %>% unique()

e2_gpt3_context_global_cat_count_wide <- e2_gpt3_context_global_cat_count %>%
  pivot_wider(names_from = "context_nr", values_from = "cat_cont_proportion")
```

FINAL FINAL PLOT:
```{r}
e2_gpt3_context_raw_final_summary <- e2_gpt3_context_raw %>% group_by(prompt, context_nr, global_category) %>% summarize(x = n() / prompt_context_count) %>% unique() %>%
  pivot_wider(values_from = "x", names_from = "context_nr") 

e2_gpt3_context_raw_final_summary_wHuman <- e2_gpt3_context_raw_final_summary %>% rbind(read_csv("../code/paper_data/e2_human_props_fixed.csv"))
```
```{r}
e2_gpt3_context_raw_final_summary_wHuman %>% 
  mutate(prompt = factor(prompt, levels = c("zero-shot", "one-shot Explanation", "one-shot QA", "one-shot CoT", "human E2"))) %>%
  mutate(global_category = factor(global_category, levels = c( 'otherCategory', 'mostSimilar', 'competitor_c2', 'competitor_c1'),
                           labels = c("unrelated option\n(carpet)", "a priori\nsimilar (pillow)", "competitor 2\n(bubble wrap)", "competitor 1\n(sleeping bag)")
                           )) %>%
  ggplot(., aes(fill = prompt, x = global_category)) +
  geom_col(aes(y = context1), position = position_dodge(preserve = "single"), color = "#575463" ) +
  geom_col(aes(y = -context2), position = position_dodge(preserve = "single"), color = "#575463" ) +
  theme_csp() + 
  theme( axis.text.y = element_text(size = 12), axis.text.x = element_text(size = 12),  legend.title = element_text(size=12), legend.text = element_text(size=12), legend.position = "right", plot.title = element_text(hjust = 0.5)) + # , axis.ticks.y = element_blank(), 
  scale_y_continuous( limits = c(-1, 1), breaks = c(-1, -0.5, 0, 0.5, 1), labels = c("1", "0.5", "0", "0.5", "1")) +
  geom_hline(yintercept = 0, color = "white", size = 1) +
  coord_flip() +
  ylab("transport <--> sleepover") +
  xlab("") +
  ggtitle("Do you have a blanket?")

ggsave("viz/e2_byPrompt_final_final.pdf", width = 6.5, height = 4 )
```


```{r}
nm_samples_categorized_e2 %>% filter(model_name == "chatGPT") %>% filter(category != 'yes') %>% group_by(is_few_shot) %>% mutate(n_resp = n()) %>% group_by(is_few_shot, category) %>% summarize(cat_count = n(), prop = cat_count / n_resp) %>% unique()
```

```{r}
e1_oneShot_Cot_davinci2 <- read_csv("../code/results/prompts/oneShotCoT_presencePenalty/GPT3-davinci-003-samples-oneShotLearner-n5-m64-cogsci-e1_categorized.csv")

e1_oneShot_Cot_davinci2 %>% 
  mutate(category = ifelse(is.na(category), "EOS", category)) %>%
  filter(category != "yes") %>%
  group_by(category) %>%
  mutate(category_count = n(),
         prop = category_count / nrow(e1_oneShot_Cot_davinci2)
         ) %>% select(category, prop) %>% unique() %>% ungroup() %>%
  add_row(category = "otherCategory", prop = 0) %>%
  mutate(category = factor(category, levels = c("competitor", "sameCategory", "otherCategory", "fullList", "other", "taciturn", "EOS")))%>%
  ggplot(., aes(x = category, y = prop, fill = category)) +
  geom_col() +
  theme_csp() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
prompts_e1_summary_labels <- prompts_e1_summary %>% group_by(category) %>%
  summarize(max_val = max(prop)) %>% 
  mutate(category = factor(category, levels = c("competitor", "sameCategory", "otherCategory", "fullList", "other", "taciturn"), labels = c("competitor\n(iced coffee)", "similar option\n(soda)", "unrelated\noption\n(Chardonnay)", "all options", "other", "no options") ))

prompts_e1_summary %>% 
  mutate(category = factor(category, levels = rev(c("taciturn", "other", "fullList", "otherCategory", "sameCategory", "competitor")), labels = rev(c("no options",  "other", "all options", "unrelated\noption\n(Chardonnay)", "similar option\n(soda)", "competitor\n(iced coffee)"  ) ))) %>%
  #mutate(category = factor(category, levels = rev(c("taciturn", "other", "fullList", "otherCategory", "sameCategory", "competitor")) )) %>%
  ggplot(., aes(x = category, y = prop, fill = prompt, label = category)) +
  geom_col(position = position_dodge(preserve = "single"), color = "#575463", width = 0.8 )+
  geom_text(inherit.aes = FALSE, data = prompts_e1_summary_labels, aes(x = category, y = max_val, label = category), stat = 'unique', nudge_y = 0.08, size = 4, check_overlap = TRUE) +
  theme_csp() +
  scale_y_continuous( limits = c(0, 0.7), breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7)) +
   theme(plot.title = element_text(hjust = 0.5), legend.position = "right",  legend.title = element_text(size=12), legend.text = element_text(size=12), axis.text.x = element_blank(), axis.ticks.x = element_blank() ) +  # axis.text.x = element_text(angle = 45, hjust = 1), 
  #coord_flip() +
  ylab("Proportion of answer type") +
  xlab("Answer type") +
  ggtitle("davinci-002: Do you have iced tea?")

#ggsave("viz/e1_human_gpt3_lessNA_explAvg_horizontal.pdf", width = 7.5, height = 4 )

human_e2 <- read_csv("data/results_105_QA-overinfo-contextDependent-freeTyping-pilot4_130_byContext_summary.csv") %>% 
  mutate(prompt = "human E2")

prompts_e2_raw <- rbind(zeroShotExample_e2_raw, oneShotExplanation_e2_raw, oneShotExample_e2_raw, oneShotQA_e2_raw, e3_pilot_wVignette_raw %>% mutate(prompt = "human E2") %>% select(global_category, context_nr, prompt, settingName))

prompts_e2 <- rbind(oneShotQA_e2, oneShotExample_e2, oneShotExplanation_e2,  zeroShotExample_e2, human_e2) %>% 
  mutate(prompt = factor(prompt, levels = c("zero-shot", "one-shot Explanation", "one-shot QA", "one-shot CoT", "human E2")))

prompts_e2 %>% 
  mutate(global_category = factor(global_category, levels = c( 'otherCategory', 'mostSimilar', 'competitor_c2', 'competitor_c1'),
                           labels = c("unrelated option\n(broom)", "a priori\nsimilar (recliner)", "competitor 2\n(stool)", "competitor 1\n(ladder)")
                           )) %>%
  ggplot(., aes(fill = prompt, x = global_category)) +
  geom_col(aes(y = context1), position = position_dodge(preserve = "single"), color = "#575463" ) +
  geom_col(aes(y = -context2), position = position_dodge(preserve = "single"), color = "#575463" ) +
  theme_csp() + 
  theme( axis.text.y = element_text(size = 12), axis.text.x = element_text(size = 12),  legend.title = element_text(size=12), legend.text = element_text(size=12), legend.position = "right", plot.title = element_text(hjust = 0.5)) + # , axis.ticks.y = element_blank(), 
  scale_y_continuous( limits = c(-1, 1), breaks = c(-1, -0.5, 0, 0.5, 1), labels = c("1", "0.5", "0", "0.5", "1")) +
  geom_hline(yintercept = 0, color = "white", size = 1) +
  coord_flip() +
  ylab("party <--> reaching window top") +
  xlab("") +
  ggtitle("Do you have a chair?")


#ggsave("viz/e2_byPrompt_vertical_final_lessNA.pdf", width = 5.5, height = 4 )
```

```{r}
diverse_zero <- read_csv("../code/results/GPT3-davinci-003-samples-zeroShotLearner-diverseQA.csv") %>% 
  mutate(prompt = "zeroShot")
diverse_one <- read_csv("../code/results/GPT3-davinci-003-samples-oneShotLearner-diverseQA.csv") %>% 
  mutate(prompt = "oneShot")
diverse_one_mismatch <- read_csv("../code/results/GPT3-davinci-003-samples-oneShotLearner-diverseQA-mismatch.csv") %>% 
  mutate(prompt = "oneShot_mismatch")
diverse_two <- read_csv("../code/results/GPT3-davinci-003-samples-twoShotLearner-diverseQA.csv") %>% 
  mutate(prompt = "twoShot")

diverse_all <- rbind(diverse_zero, diverse_one, diverse_one_mismatch, diverse_two)
```

```{r}
diverse_all_summary <- diverse_all %>% 
  filter(!is.na(response_type)) %>%
  group_by(prompt) %>%
  mutate(num_resp = n()) %>%
  ungroup() %>%
  group_by(prompt, response_type) %>%
  summarize(num_cat = n(), prop = num_cat / num_resp) %>% unique()

diverse_all_byItem_summary <- diverse_all %>% 
  filter(!is.na(response_type)) %>%
  group_by(prompt, itemName) %>%
  mutate(num_resp = n()) %>%
  ungroup() %>%
  group_by(prompt, itemName, response_type) %>%
  summarize(num_cat = n(), prop = num_cat / num_resp) %>% unique()
```

```{r, fig.height=10, fig.width=7}
diverse_all_byItem_summary %>% 
  mutate(response_type = factor(response_type),
         prompt = factor(prompt)) %>%
  ggplot(., aes(x = response_type, y = prop, fill = prompt)) +
  geom_col(position = position_dodge(preserve = "single")) +
  facet_wrap(itemName~., ncol=2) +
  theme_csp()
```